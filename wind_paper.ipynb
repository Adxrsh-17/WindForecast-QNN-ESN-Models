{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b44cf5",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em; font-weight:bold;\">ESN-ONLY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c664a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# === Train & Predict ===\u001b[39;00m\n\u001b[32m     75\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m esn = \u001b[43mESN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m esn.fit(X_train, y_train)\n\u001b[32m     78\u001b[39m y_pred_scaled = esn.predict(X_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mESN.__init__\u001b[39m\u001b[34m(self, input_dim, reservoir_size, spectral_radius, sparsity, reg, leaky_rate, washout)\u001b[39m\n\u001b[32m     50\u001b[39m W = np.random.rand(reservoir_size, reservoir_size) - \u001b[32m0.5\u001b[39m\n\u001b[32m     51\u001b[39m W[np.random.rand(*W.shape) > sparsity] = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m eig_val = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mabs\u001b[39m(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigvals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.W = W * (spectral_radius / eig_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\linalg\\_linalg.py:1224\u001b[39m, in \u001b[36meigvals\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m   1220\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->D\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_eigenvalues_nonconvergence,\n\u001b[32m   1222\u001b[39m               invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m, over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1223\u001b[39m               under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m     w = \u001b[43m_umath_linalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigvals\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isComplexType(t):\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(w.imag == \u001b[32m0\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# === Publication Style ===\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "# === Save Directory ===\n",
    "save_dir = r\"C:\\Users\\Adarsh Pradeep\\OneDrive\\Desktop\\Adarsh_Personal\\PAPERS_TO_PUBLISH\\plotsresults\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# === Load and Preprocess Data ===\n",
    "df = pd.read_csv(\"wind_paper.csv\")\n",
    "df = df[df['Patv'] > 0].drop(['Tmstamp', 'TurbID'], axis=1)\n",
    "N_LAGS = 36\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    df[f'Patv_lag_{lag}'] = df['Patv'].shift(lag)\n",
    "df['Patv_diff'] = df['Patv'].diff()\n",
    "df['RollingMean'] = df['Patv'].rolling(window=6).mean()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop('Patv', axis=1).values\n",
    "y = df['Patv'].values.reshape(-1, 1)\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "\n",
    "# === ESN Class ===\n",
    "class ESN:\n",
    "    def __init__(self, input_dim, reservoir_size=2000, spectral_radius=0.98, sparsity=0.05,\n",
    "                 reg=1e-3, leaky_rate=0.15, washout=150):\n",
    "        self.input_dim = input_dim + 1\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.reg = reg\n",
    "        self.leaky_rate = leaky_rate\n",
    "        self.washout = washout\n",
    "        self.Win = np.random.uniform(-0.5, 0.5, (reservoir_size, self.input_dim))\n",
    "        W = np.random.rand(reservoir_size, reservoir_size) - 0.5\n",
    "        W[np.random.rand(*W.shape) > sparsity] = 0\n",
    "        eig_val = max(abs(np.linalg.eigvals(W)))\n",
    "        self.W = W * (spectral_radius / eig_val)\n",
    "    def _update(self, state, input_):\n",
    "        u = np.concatenate((input_, [1]))\n",
    "        pre_activation = np.dot(self.Win, u) + np.dot(self.W, state)\n",
    "        return (1 - self.leaky_rate) * state + self.leaky_rate * np.tanh(pre_activation)\n",
    "    def fit(self, X, y):\n",
    "        states = []\n",
    "        state = np.zeros(self.reservoir_size)\n",
    "        for x in X:\n",
    "            state = self._update(state, x)\n",
    "            states.append(state.copy())\n",
    "        states = np.array(states)\n",
    "        X_eff, y_eff = states[self.washout:], y[self.washout:]\n",
    "        self.Wout = Ridge(alpha=self.reg, fit_intercept=False).fit(X_eff, y_eff).coef_.T.flatten()\n",
    "    def predict(self, X):\n",
    "        preds, state = [], np.zeros(self.reservoir_size)\n",
    "        for x in X:\n",
    "            state = self._update(state, x)\n",
    "            preds.append(state @ self.Wout)\n",
    "        return np.array(preds)\n",
    "\n",
    "# === Train & Predict ===\n",
    "start = time.time()\n",
    "esn = ESN(input_dim=X.shape[1])\n",
    "esn.fit(X_train, y_train)\n",
    "y_pred_scaled = esn.predict(X_test)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "y_test_actual = y_scaler.inverse_transform(y_test)\n",
    "end = time.time()\n",
    "\n",
    "# === Metrics ===\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "mape = np.mean(np.abs((y_test_actual - y_pred) / y_test_actual)) * 100\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "train_time = end - start\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%, R2: {r2:.4f}, TrainTime: {train_time:.2f}s\")\n",
    "\n",
    "df_test = df.iloc[split:].copy()\n",
    "df_test['Error'] = abs(df_test['Patv'].values - y_pred.flatten())\n",
    "\n",
    "# === Plots Section (Auto-save, 300 DPI, .jpg) ===\n",
    "\n",
    "# 1. Forecast vs Actual\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual[:100], label='Actual', color='black')\n",
    "plt.plot(y_pred[:100], label='Predicted', color='orange')\n",
    "plt.title(\"Forecast vs Actual (First 100 Samples)\", fontsize=22)\n",
    "plt.xlabel(\"Sample Index\", fontsize=20)\n",
    "plt.ylabel(\"Power Output (Patv) [kW]\", fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_forecast_vs_actual.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Residual Distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_test['Error'], kde=True, color='red')\n",
    "plt.title(\"Residual Distribution\", fontsize=22)\n",
    "plt.xlabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.ylabel(\"Frequency\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_residual_distribution.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Error Over Time\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_test['Error'][:300], label='Error', color='purple')\n",
    "plt.title(\"Prediction Error Over Time\", fontsize=22)\n",
    "plt.xlabel(\"Sample Index\", fontsize=20)\n",
    "plt.ylabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_error_over_time.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4. Scatter Plot: Actual vs Predicted\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test_actual, y_pred, alpha=0.4)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--')\n",
    "plt.title(\"Scatter Plot: Actual vs Predicted\", fontsize=22)\n",
    "plt.xlabel(\"Actual Power Output (kW)\", fontsize=20)\n",
    "plt.ylabel(\"Predicted Power Output (kW)\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_scatter_actual_pred.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. Lag Correlation Plot (Autocorrelation)\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = plt.gca()\n",
    "plot_acf(df['Patv'], lags=30, ax=ax)\n",
    "plt.title(\"Lag Correlation Plot (Autocorrelation)\", fontsize=22)\n",
    "plt.xlabel(\"Lag\", fontsize=20)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_autocorrelation_patv.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 6. Error Box Plot by Month\n",
    "df_test['Month'] = pd.to_datetime(df_test.index, errors='coerce').month\n",
    "month_order = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "month_names = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Month', y='Error', data=df_test, hue='Month', palette=\"Set2\",\n",
    "            order=month_order, dodge=False, legend=False)\n",
    "plt.xticks(ticks=range(12), labels=month_names, fontsize=18, rotation=45)\n",
    "plt.title(\"Error Box Plot by Month\", fontsize=22)\n",
    "plt.xlabel(\"Month\", fontsize=20)\n",
    "plt.ylabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_error_boxplot_by_month.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 7. Box Plot of Errors (per 500 samples)\n",
    "chunks = len(df_test) // 500\n",
    "residuals_trimmed = df_test['Error'].values[:chunks * 500]\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(data=pd.DataFrame(residuals_trimmed.reshape(-1, 500)).T, color='skyblue')\n",
    "plt.title(\"Box Plot of Errors (per 500 samples)\", fontsize=22)\n",
    "plt.xlabel(\"Chunk Index\", fontsize=20)\n",
    "plt.ylabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_boxplot_errors_per500.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 8. Feature Importance (Ridge Coef Magnitude)\n",
    "feature_importance = np.abs(esn.Wout)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(feature_importance)), feature_importance, color='seagreen')\n",
    "plt.title(\"Feature Importance (Ridge Coef Magnitude)\", fontsize=22)\n",
    "plt.xlabel(\"Feature Index\", fontsize=20)\n",
    "plt.ylabel(\"Importance\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"esn_feature_importance.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 9. Time-Series Decomposition\n",
    "decomp = seasonal_decompose(df['Patv'].values[:500], model='additive', period=24)\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.suptitle(\"Time-Series Decomposition of Power Output (Patv)\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(os.path.join(save_dir, \"esn_ts_decomposition_patv.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa114a",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em; font-weight:bold;\">gradient_boost</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Set style for publication\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "# 1. Directory Setup\n",
    "save_dir = r\"C:\\Users\\Adarsh Pradeep\\OneDrive\\Desktop\\Adarsh_Personal\\PAPERS_TO_PUBLISH\\plotsresults\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 2. Load and Preprocess Data\n",
    "df = pd.read_csv(\"wind_paper.csv\")\n",
    "df = df[df['Patv'] > 0].drop(['Tmstamp', 'TurbID'], axis=1)\n",
    "N_LAGS = 36\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    df[f'Patv_lag_{lag}'] = df['Patv'].shift(lag)\n",
    "df['Patv_diff'] = df['Patv'].diff()\n",
    "df['RollingMean'] = df['Patv'].rolling(window=6).mean()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop('Patv', axis=1).values\n",
    "y = df['Patv'].values.reshape(-1, 1)\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "\n",
    "# 3. ESN Class Definition\n",
    "class ESN:\n",
    "    def __init__(self, input_dim, reservoir_size=2000, spectral_radius=0.98, sparsity=0.05,\n",
    "                 reg=1e-3, leaky_rate=0.15, washout=150):\n",
    "        self.input_dim = input_dim + 1\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.reg = reg\n",
    "        self.leaky_rate = leaky_rate\n",
    "        self.washout = washout\n",
    "        self.Win = np.random.uniform(-0.5, 0.5, (reservoir_size, self.input_dim))\n",
    "        W = np.random.rand(reservoir_size, reservoir_size) - 0.5\n",
    "        W[np.random.rand(*W.shape) > sparsity] = 0\n",
    "        eig_val = max(abs(np.linalg.eigvals(W)))\n",
    "        self.W = W * (spectral_radius / eig_val)\n",
    "\n",
    "    def _update(self, state, input_):\n",
    "        u = np.concatenate((input_, [1]))\n",
    "        pre_activation = np.dot(self.Win, u) + np.dot(self.W, state)\n",
    "        return (1 - self.leaky_rate) * state + self.leaky_rate * np.tanh(pre_activation)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        states = []\n",
    "        state = np.zeros(self.reservoir_size)\n",
    "        for x in X:\n",
    "            state = self._update(state, x)\n",
    "            states.append(state.copy())\n",
    "        states = np.array(states)\n",
    "        X_eff, y_eff = states[self.washout:], y[self.washout:]\n",
    "        self.Wout = Ridge(alpha=self.reg, fit_intercept=False).fit(X_eff, y_eff).coef_.T.flatten()\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds, state = [], np.zeros(self.reservoir_size)\n",
    "        for x in X:\n",
    "            state = self._update(state, x)\n",
    "            preds.append(state @ self.Wout)\n",
    "        return np.array(preds)\n",
    "\n",
    "# 4. Training & Prediction\n",
    "start = time.time()\n",
    "esn = ESN(input_dim=X.shape[1])\n",
    "esn.fit(X_train, y_train)\n",
    "y_pred_scaled = esn.predict(X_test)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "y_test_actual = y_scaler.inverse_transform(y_test)\n",
    "end = time.time()\n",
    "\n",
    "# 5. Metrics Calculation\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "mape = np.mean(np.abs((y_test_actual - y_pred) / y_test_actual)) * 100\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "train_time = end - start\n",
    "print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%, R2: {r2:.4f}, TrainTime: {train_time:.2f}s\")\n",
    "\n",
    "df_test = df.iloc[split:].copy()\n",
    "df_test['Error'] = abs(df_test['Patv'].values - y_pred.flatten())\n",
    "\n",
    "# === PLOTS SECTION: All plots save in .jpg, dpi=300 ===\n",
    "\n",
    "# 1. Forecast vs Actual\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual[:100], label='Actual', color='black')\n",
    "plt.plot(y_pred[:100], label='Predicted', color='orange')\n",
    "plt.title(\"Forecast vs Actual (First 100 Samples)\", fontsize=22)\n",
    "plt.xlabel(\"Sample Index\", fontsize=20)\n",
    "plt.ylabel(\"Power Output (Patv) [kW]\", fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"forecast_vs_actual.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Residual Distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_test['Error'], kde=True, color='red')\n",
    "plt.title(\"Residual Distribution\", fontsize=22)\n",
    "plt.xlabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.ylabel(\"Frequency\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"residual_distribution.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Error Over Time\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_test['Error'][:300], label='Error', color='purple')\n",
    "plt.title(\"Prediction Error Over Time\", fontsize=22)\n",
    "plt.xlabel(\"Sample Index\", fontsize=20)\n",
    "plt.ylabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"error_over_time.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4. Scatter Plot: Actual vs Predicted\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test_actual, y_pred, alpha=0.4)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--')\n",
    "plt.title(\"Scatter Plot: Actual vs Predicted\", fontsize=22)\n",
    "plt.xlabel(\"Actual Power Output (kW)\", fontsize=20)\n",
    "plt.ylabel(\"Predicted Power Output (kW)\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"scatter_actual_vs_predicted.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. Lag Correlation Plot (Autocorrelation)\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = plt.gca()\n",
    "plot_acf(df['Patv'], lags=30, ax=ax)\n",
    "plt.title(\"Lag Correlation Plot (Autocorrelation of Power Output)\", fontsize=22)\n",
    "plt.xlabel(\"Lag\", fontsize=20)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"autocorrelation_patv.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 6. Error Box Plot by Month\n",
    "df_test['Month'] = pd.to_datetime(df_test.index, errors='coerce').month\n",
    "month_order = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "month_names = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Month', y='Error', data=df_test, hue='Month', palette=\"Set2\",\n",
    "            order=month_order, dodge=False, legend=False)\n",
    "plt.xticks(ticks=range(12), labels=month_names, fontsize=18, rotation=45)\n",
    "plt.title(\"Error Box Plot by Month\", fontsize=22)\n",
    "plt.xlabel(\"Month\", fontsize=20)\n",
    "plt.ylabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"error_boxplot_by_month.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 7. Box Plot of Errors (per 500 samples)\n",
    "chunks = len(df_test) // 500\n",
    "residuals_trimmed = df_test['Error'].values[:chunks * 500]\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(data=pd.DataFrame(residuals_trimmed.reshape(-1, 500)).T, color='skyblue')\n",
    "plt.title(\"Box Plot of Errors (per 500 samples)\", fontsize=22)\n",
    "plt.xlabel(\"Chunk Index\", fontsize=20)\n",
    "plt.ylabel(\"Absolute Error (kW)\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"boxplot_errors_per500.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 8. Feature Importance (Ridge Coef Magnitude)\n",
    "feature_importance = np.abs(esn.Wout)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(feature_importance)), feature_importance, color='seagreen')\n",
    "plt.title(\"Feature Importance (Ridge Coef Magnitude)\", fontsize=22)\n",
    "plt.xlabel(\"Feature Index\", fontsize=20)\n",
    "plt.ylabel(\"Importance\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"feature_importance.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 9. Time-Series Decomposition\n",
    "decomp = seasonal_decompose(df['Patv'].values[:500], model='additive', period=24)\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.suptitle(\"Time-Series Decomposition of Power Output (Patv)\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(os.path.join(save_dir, \"ts_decomposition_patv.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e05463",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em; font-weight:bold;\">QUANTUM_AI</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.qnn import KerasLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set reproducibility for results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set number of qubits\n",
    "nq = 4\n",
    "dev = qml.device(\"default.qubit\", wires=nq)\n",
    "\n",
    "# Make QNode TF-aware\n",
    "@qml.qnode(dev, interface=\"tf\")\n",
    "def qc(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(nq), rotation='Y')\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(nq))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(nq)]\n",
    "\n",
    "# Define weight shapes for the PQC\n",
    "weight_shapes = {\"weights\": (3, nq, 3)}\n",
    "\n",
    "# Create the quantum Keras layer\n",
    "qlayer = KerasLayer(qc, weight_shapes=weight_shapes, output_dim=nq)\n",
    "\n",
    "# Build the full hybrid model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(nq,)),\n",
    "    Dense(nq, activation=\"relu\"),\n",
    "    qlayer,\n",
    "    Dense(1, activation=\"linear\"),\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Generate synthetic training data (replace with real data as needed)\n",
    "X = np.random.rand(100, nq)\n",
    "y = np.random.rand(100, 1)\n",
    "\n",
    "# Train and capture training history\n",
    "history = model.fit(X, y, epochs=20, batch_size=10, verbose=1)\n",
    "\n",
    "# Save training loss curve in high-resolution for publication\n",
    "save_dir = r\"C:\\Users\\Adarsh Pradeep\\OneDrive\\Desktop\\Adarsh_Personal\\PAPERS_TO_PUBLISH\\plotsresults\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], marker='o', linewidth=3)\n",
    "plt.title(\"QNN Training Loss Curve\", fontsize=22)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"Loss (MSE)\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"qnn_training_loss_curve.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4ed0e",
   "metadata": {},
   "source": [
    "ESN+DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b849106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n",
      "Hybrid Model Metrics:\n",
      "RMSE: 26.2048, MAE: 13.2853, MAPE: 10.67%, R2: 0.9953, Train Time: 140.05s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "save_dir = r\"C:\\Users\\Adarsh Pradeep\\OneDrive\\Desktop\\Adarsh_Personal\\PAPERS_TO_PUBLISH\\plotsresults\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load & Preprocess Data\n",
    "df = pd.read_csv(\"wind_paper.csv\")\n",
    "df = df[df['Patv'] > 0].drop(['Tmstamp', 'TurbID'], axis=1)\n",
    "N_LAGS = 36\n",
    "for lag in range(1, N_LAGS + 1):\n",
    "    df[f'Patv_lag_{lag}'] = df['Patv'].shift(lag)\n",
    "df['Patv_diff'] = df['Patv'].diff()\n",
    "df['RollingMean'] = df['Patv'].rolling(window=6).mean()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop('Patv', axis=1).values\n",
    "y = df['Patv'].values.reshape(-1, 1)\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "\n",
    "# ESN Class\n",
    "class ESN:\n",
    "    def __init__(self, input_dim, reservoir_size=900, spectral_radius=1.0, sparsity=0.05, reg=1e-5, leaky_rate=0.3, washout=60):\n",
    "        self.input_dim = input_dim + 1\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.reg = reg\n",
    "        self.leaky_rate = leaky_rate\n",
    "        self.washout = washout\n",
    "        self.Win = np.random.uniform(-0.5, 0.5, (reservoir_size, self.input_dim))\n",
    "        W = np.random.rand(reservoir_size, reservoir_size) - 0.5\n",
    "        W[np.random.rand(*W.shape) > sparsity] = 0\n",
    "        eig_val = max(abs(np.linalg.eigvals(W)))\n",
    "        self.W = W * (spectral_radius / eig_val)\n",
    "    def _update(self, state, input_):\n",
    "        u = np.concatenate((input_, [1]))\n",
    "        pre_activation = np.dot(self.Win, u) + np.dot(self.W, state)\n",
    "        return (1 - self.leaky_rate) * state + self.leaky_rate * np.tanh(pre_activation)\n",
    "    def fit(self, X, y):\n",
    "        states = []\n",
    "        state = np.zeros(self.reservoir_size)\n",
    "        for x in X:\n",
    "            state = self._update(state, x)\n",
    "            states.append(state.copy())\n",
    "        states = np.array(states)\n",
    "        X_eff, y_eff = states[self.washout:], y[self.washout:]\n",
    "        self.Wout = Ridge(alpha=self.reg, fit_intercept=False).fit(X_eff, y_eff).coef_.T.flatten()\n",
    "        self.trained_states = states\n",
    "    def predict(self, X):\n",
    "        preds, state = [], np.zeros(self.reservoir_size)\n",
    "        for x in X:\n",
    "            state = self._update(state, x)\n",
    "            preds.append(state @ self.Wout)\n",
    "        return np.array(preds)\n",
    "\n",
    "# Hybrid/Dense model\n",
    "def build_hybrid(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train ESN\n",
    "start = time.time()\n",
    "esn = ESN(input_dim=X.shape[1])\n",
    "esn.fit(X_train, y_train)\n",
    "esn_pred_train = esn.predict(X_train)\n",
    "esn_pred_test = esn.predict(X_test)\n",
    "\n",
    "# Hybrid Training\n",
    "X_hybrid_train = esn_pred_train.reshape(-1, 1)\n",
    "X_hybrid_test = esn_pred_test.reshape(-1, 1)\n",
    "hybrid_model = build_hybrid(1)\n",
    "hybrid_model.fit(X_hybrid_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "y_pred_scaled = hybrid_model.predict(X_hybrid_test)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = y_scaler.inverse_transform(y_test)\n",
    "end = time.time()\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "mape = np.mean(np.abs((y_test_actual - y_pred) / y_test_actual)) * 100\n",
    "r2 = r2_score(y_test_actual, y_pred)\n",
    "train_time = end - start\n",
    "print(\"Hybrid Model Metrics:\")\n",
    "print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%, R2: {r2:.4f}, Train Time: {train_time:.2f}s\")\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual[:100], label='Actual', color='black')\n",
    "plt.plot(y_pred[:100], label='Predicted', color='orange')\n",
    "plt.title(\"Forecast vs Actual (Hybrid Model)\", fontsize=22)\n",
    "plt.xlabel(\"Sample Index\", fontsize=20)\n",
    "plt.ylabel(\"Power Output (Patv) [kW]\", fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"hybrid_forecast_vs_actual.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test_actual, y_pred, alpha=0.4)\n",
    "plt.plot([y_test_actual.min(), y_test_actual.max()], [y_test_actual.min(), y_test_actual.max()], 'k--')\n",
    "plt.title(\"Hybrid Model: Actual vs Predicted\", fontsize=22)\n",
    "plt.xlabel(\"Actual Power Output (kW)\", fontsize=20)\n",
    "plt.ylabel(\"Predicted Power Output (kW)\", fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"hybrid_scatter_actual_pred.jpg\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
